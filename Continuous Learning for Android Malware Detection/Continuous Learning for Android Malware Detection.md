# Continuous Learning for Android Malware Detection (持续学习Android恶意软件检测)
## Abstract
suiran ML在Android的恶意软件的检测中有着很好的性能，但是他们并不适用于开放网络环境，通过本文的实验可以知道，针对一个持续增加的数据集，检测模型仅仅在六个月之后之后，其F1分数就从99降到了76，这种情况的发生正是由概念漂移导致的，而本文结合了主动学习和对比学习，提出了一种检测概念漂移的新方法。  
## Introduction  
### Motivation  
- 静态模型无法适应概念漂移，当时间越来越长的时候，模型的效率会大幅度下降  
- 主动学习样本选择效率低，现有主动学习方法（如不确定性采样）仅依赖分类器的预测置信度（如Softmax输出），忽略了样本间的相似性关系，可能漏选关键漂移样本（如新恶意家族）。    
- 类别不平衡问题严重，真实数据中94%为良性应用，传统对比学习（如CADE）在嵌入空间中将不同恶意家族视为完全独立类别，导致新恶意样本易被误判为良性（见图3左）。 
- 冷启动训练效率低，传统方法每次更新模型时需从头训练（冷启动），但新标注样本占比极小（如每月新增样本仅占训练集的1%），模型难以快速适应新趋势。
- 在线学习：在每个新的Android应用程序被标记后持续训练模型，这种方法比论文的方法要贵得多。 
### Contribution    
- 分层对比学习：提出一种层级化嵌入空间建模方法，强制同一恶意软件家族内样本高度相似、不同家族间弱相似、恶意与良性样本显著分离。
- 伪损失样本选择：首次提出基于对比学习嵌入空间的不确定性度量方法（伪损失），通过计算测试样本与训练集的对比损失值，量化模型对未知样本的困惑度。
- 温启动训练：在主动学习中持续微调模型（而非冷启动），通过保留历史权重，缓解新旧样本数量不平衡问题。
## Methodology
![框架图](https://github.com/makabal/paper/blob/main/tupian/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-03-27%20193153.png?raw=true)  
总体流程大致如下：训练——>分层对比编码器——>预测标签——>通过伪损失函数筛选不确定样本——>选择最高的那几个给人工标注，扩充数据库。
### Hierarchical Contrastive Learning
对比学习的问题：因为在现实中，大多数的样本往往是良性的，所以对比学习的模型很有可能将未知的恶意软件样本与良性样本相似。
![两种对比学习的差距](https://github.com/makabal/paper/blob/main/tupian/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-03-27%20201743.png?raw=true)  
通过上图我们可以发现CADE中使用的对比学习编码器很容易将新的类别归类到良性样本当中，而分层的对比学习编码器，可以在第一层的时候很好的将恶意软件和良性样本分离开来，之后还可以通过第二层的编码器，将不同家族的恶意软件分开，很好的解决了类别不平衡的问题。    
如何将良性样本和恶意样本分开？    
在分层对比分类器中，本文将相似程度分成了三种：弱相似，相似，强相似。  
通过f (x) = g(enc(x))这样一个函数，其中x代表样本，enc(x)代表嵌入函数，目的是为了学习到一个具有以下特征的嵌入空间：
- 同一恶意软件家族的样本嵌入高度相似  
- 不同家族的恶意样本弱相似  
- 恶意与良性样本显著分离  
通过损失函数，可以鼓励f(x)预测正确的标签，同时让编码器满足以上三个性质，而这一点是通过对比两个样本在嵌入空间里的距离得到的。   
最终将样本分成两个集合，一个集合是恶意软件家族，一个是良性样本。  
- 这个损失函数将作为分层对比损失的第一项，即只要距离超过 m 就会受到惩罚，迫使它们靠得更近；  
- 对于同一恶意家族的样本，任何距离都会产生惩罚，从而尽量将它们紧密聚集；  
- 对于不同类别的样本，只有当它们的距离不足 2m 时才会产生惩罚，从而使不同类别的样本被明显分开。  
具体如下所示：  
![分层对比损失函数](https://github.com/makabal/paper/blob/main/tupian/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-03-27%20211344.png?raw=true)    
而总的损失函数就是对比损失函数加上交叉熵损失函数。   
![联合损失函数](https://github.com/makabal/paper/blob/main/tupian/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-03-27%20211750.png?raw=true)
### Pseudo Loss Sample Selector
在一般的监督分类模型里，如果我们想度量模型对某个样本的不确定度，最常见的方式是看模型输出的“置信度”（例如 softmax 输出的最大概率，或其相反量 1 - max_probability 等）。但是在对比学习 (contrastive learning) 中，模型训练时用到的损失往往来自“成对 (pairwise)”或“成组 (triplet, batchwise)”的样本比较：一个样本的学习效果并不是只依赖它本身，而是取决于它与其它正样本（相似样本）或负样本（不相似样本）之间的距离是否满足期望。因此，要度量某个单个新样本在对比学习框架下的“不确定度”，需要一种新的方法。   
其具体的实现方法如下：  
首先通过分类器对测试数据（也就是新的数据）打上伪标签，然后将测试样本和训练样本的标签进行对比，比如，有1000个训练数据，其中400恶意，600良性，测试集100个，30恶意，70良性，而这些样本都会被映射到先前学习好的嵌入空间里面，在这个空间里，恶意样本和良性样本应该是分开且聚集的，如果样本的伪标签和样本在嵌入空间中实际的位置不同，那么他们的损失就大，也代表了错误的可能性就高。     
通过上述方法，对100个测试数据进行排序，排名越靠前，置信度就越低，也就越需要人工标注，这样就能大大增强人工标注的效率，因为所挑选人工标注的样本都是置信度低的。     
## Evaluation






