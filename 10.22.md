# 论文阅读 
## 《Label-Free Multivariate Time Series Anomaly Detection》
### 传统方法的问题：
#### 多元时间序列异常检测   
传统方法常多基于单类分类(OCC)，简单来说就是训练集全部为正样本。   
而且在现实中，训练数据往往存在噪声标签，也就是不准确的标签，这会导致模型过拟合异常，性能下降。    
  ![](https://github.com/makabal/paper/blob/main/tupian/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-10-22%20095831.png?raw=true)    
  基于此，本文提出了一种新的检测方法——MTGFlow。    
### 方法概述
![](https://github.com/makabal/paper/blob/main/tupian/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-10-22%20103713.png?raw=true)
#### 传统GNN  
将GNN应用于时间序列异常检测，核心思想是：时间序列数据点之间不是独立的，它们存在着复杂的、结构化的相互关系。    
##### 1.构建图  
- 节点：通常代表多元时间序列中的每一个变量（实体）。
- 边：代表变量之间的关系或依赖。
  - 静态预定义图：根据物理连接或先验知识。
  - 动态学习图（如MTGFlow论文中所用）：使用自注意力机制等，让模型自己从数据中学习每两个变量之间的关联强度。    
##### 2.消息传递
- 初始化：每个节点用其当前时刻的时间序列值作为初始状态。
- 聚合：对于每个节点（例如“温度传感器A”），GNN会去收集其所有邻居节点（如与A相连的压力传感器B、流速传感器C）的信息。
- 更新：节点A结合自己的信息和从邻居聚合来的信息，更新自己的状态。这个新状态就包含了其邻居的上下文信息。
这个过程会进行多轮，使得信息能够在图中传播得更远。最终，每个节点都获得了一个富含其所在局部图结构信息的增强表示。   
##### 3.结合时间建模
- 图卷积 + RNN/Transformer：
  - 在每个时间步 t，使用GNN处理当前时刻的图结构数据，得到所有节点的空间增强表示。
  - 然后将每个节点的增强表示序列输入到RNN（如LSTM、GRU）或Transformer中，来捕捉其时间动态。
- 时空图神经网络
