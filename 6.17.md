# GZSL问题
## GZSL的定义、目标与核心挑战
广义零样本学习（GZSL）是机器学习领域的一个前沿方向，旨在解决传统深度学习模型在面对训练过程中未曾出现的类别时识别能力受限的问题。

### GZSL的定义与目标
GZSL的核心目标是训练一个模型，使其能够在监督学习过程中，即使某些输出类别在训练时是未知（即“未见类”）的情况下，依然能够对数据样本进行准确分类 。这与传统深度学习模型形成鲜明对比，后者通常需要为每个类别提供大量的标注数据才能进行有效识别 。   

为了克服这一挑战，GZSL利用已知（源）类别和未知（目标）类别的语义信息，以弥合两者之间的知识鸿沟 。语义信息可以是人工定义的属性向量，例如物体的颜色或形状，也可以是自动从大规模文本语料库中提取的词向量，这些向量能够捕捉词语之间的相似性和差异 。GZSL的根本动机在于模仿人类的识别能力：人类能够通过已有的知识和对新事物的描述来识别从未直接接触过的对象，例如一个孩子在见过马之后，通过描述其黑白条纹即可识别斑马 。GZSL正是试图赋予机器这种泛化能力，使其能够同时识别已知和未知类别的样本，这使其成为零样本学习（ZSL）的“实用版本” 。传统的ZSL仅关注在测试阶段识别未见类样本，这在实际应用中并不完全符合真实世界的识别条件，因为实际场景中已知类样本通常比未见类样本更为常见，且需要同时识别两者 。   

### GZSL面临的核心挑战
尽管GZSL致力于模仿人类的识别能力，但在实际实现中，它面临着几个关键的、相互关联的挑战，这些挑战限制了模型的泛化性能。

#### 枢纽问题（Hubness Problem）
枢纽问题是早期零样本学习和广义零样本学习方法在学习语义嵌入空间并利用最近邻搜索进行识别时遇到的一个显著挑战 。这个问题源于“维度诅咒”效应，即在高维空间中，某些样本（被称为“枢纽”）会异常频繁地出现在许多其他样本的k-最近邻集合中 。这意味着，在语义空间中，大量不同的映射向量可能被少数共同项所包围，导致分类器倾向于将新的测试样本错误地归类到这些“枢纽”类别，从而降低了模型区分不同类别的能力，尤其是在高维特征空间中，这使得准确识别变得困难 。   

#### 投影域偏移问题（Projection Domain Shift Problem）
投影域偏移是GZSL和ZSL方法面临的另一个核心挑战 。这些模型通常首先利用已知类别的数据样本来学习视觉空间和语义空间之间的映射函数。然而，视觉空间和语义空间是两种本质上不同的模态，它们的内在结构和数据分布可能存在显著差异。更重要的是，已知类别和未知类别的数据样本在类别上是完全不相交的，甚至可能在语义上不相关，这导致了两者之间存在较大的“域差距” 。当模型仅基于已知类数据学习映射函数时，这种域差距会导致学习到的映射函数对未知类产生偏差，将未知类别的视觉特征投影到远离其真实语义特征的位置 。图4a展示了一个理想的无偏映射，其中已知和未知类别的投影视觉样本都围绕其语义特征。然而，在实践中，如图4b所示，训练样本和测试样本的分离导致为已知类别学习的映射函数会将未知类别的视觉特征投影到远离其语义特征的区域 。这个问题在GZSL中尤为突出，因为在预测阶段，模型需要同时识别已知和未知类别，而训练过程中对已知类视觉特征的访问使得模型自然偏向于这些类别 。因此，学习一个精确的、无偏的映射函数对于GZSL模型的有效性至关重要。   

#### 偏见问题（Bias Problem）
偏见问题是GZSL任务中普遍存在的第三个核心挑战 。由于GZSL模型主要利用已知类别的数据样本进行训练，它们在学习过程中会自然而然地偏向于这些在训练中“见过”的类别。这种偏向性导致模型倾向于将来自未知类别的数据样本错误地分类为已知类别中的某个成员 。这种现象在大多数ZSL方法中也普遍存在，且难以有效解决 。为了缓解这一问题，研究者提出了多种策略，例如“校准堆叠”（calibrated stacking）和“新颖性检测器”（novelty detector） 。校准堆叠通过引入一个校准因子来平衡识别已知和未知类别数据样本之间的权衡，该因子可以被解释为未知类样本的先验似然，从而调整分类器的决策边界 。新颖性检测器则旨在识别测试样本是否属于已知类别，从而将问题分解为已知类识别和未知类识别两个子任务 。 

## GZSL核心方法论：基于嵌入的方法 

基于嵌入的方法是GZSL领域中一类重要的技术，其核心在于通过学习一个映射函数，将不同模态（如视觉和语义）的数据投影到同一个共享空间中进行识别。

### 基本原理与嵌入空间
基于嵌入的方法的核心思想是学习一个嵌入空间，将已知类别的低级视觉特征与其对应的语义向量关联起来 。一旦这个映射函数被学习到，它就可以用于识别新颖类别，通过测量嵌入空间中数据样本的原型表示和预测表示之间的相似度来进行分类 。   

根据映射的方向和目标空间，嵌入空间可以分为以下几种类型：

- 语义嵌入（Semantic Embedding）  
语义嵌入模型学习一个从视觉空间到语义空间的“前向”投影函数 。其目标是将所有属于某个类别的图像的视觉特征映射到其对应的真实标签语义嵌入附近，从而在语义空间中执行分类 。一旦获得最佳投影函数，即可通过最近邻搜索进行识别 。

- 视觉嵌入（Visual Embedding）   
视觉嵌入模型则学习一个将语义表示（如属性或词向量）“反向”映射到视觉空间的投影函数 。其目标是使语义表示与其对应的视觉特征在视觉空间中保持接近，并在此空间中进行分类 。   

- 潜在嵌入（Latent Embedding）   
与前两种方法不同，潜在嵌入模型旨在将视觉特征和语义表示都投影到一个共同的潜在空间L 。这种方法的核心在于探索不同模态之间的共同语义属性，从而克服直接在视觉或语义空间之间映射所面临的挑战，特别是缓解了枢纽问题 。一个理想的潜在空间应满足两个关键条件：类内紧凑性（同一类别的样本在潜在空间中聚集）和类间可分离性（不同类别的样本在潜在空间中能够被清晰区分） 。

## GZSL核心方法论：基于生成的方法
基于生成的方法是GZSL领域的另一大类核心技术，其根本策略是通过合成未知类别的视觉样本来将GZSL问题转化为传统的监督学习问题。

### 基本原理与生成模型
基于生成的方法的核心思想是学习一个模型，根据已知类别的样本和已知与未知类别的语义表示，为未知类别生成图像或视觉特征 。通过为未知类别生成样本，GZSL问题可以有效转化为一个传统的监督学习问题 。   

生成的数据样本需要满足两个相互冲突但至关重要的条件：首先，它们必须与真实样本在语义上相关，即能够准确反映未知类别的特征；其次，它们必须具有足够的判别性，以便分类算法能够轻松地区分不同类别 。   

生成对抗网络（GANs）是基于生成方法中的一个突出代表。GANs通过计算样本的联合分布来生成新的数据样本，利用类别条件密度和类别先验概率 。它由两个相互对抗的组件组成：一个生成器（G）和一个判别器（D） 。生成器利用语义属性和随机噪声来生成视觉特征，而判别器则负责区分这些生成的视觉特征与真实的视觉特征 。当生成器学会根据其语义表示为已知类别合成数据样本时，它就可以通过未知类别的语义表示来生成未知类别的数据样本 。   

GANs在解决偏差问题上表现出更高的效率，因为它们能够为未知类别合成视觉特征 。这使得已知类别（Acc_s）和未知类别（Acc_u）的准确性表现略微平衡，从而获得更高的调和平均值（H）。   

然而，原始GAN模型存在显著劣势：它们难以训练，且训练过程通常不稳定 。模式崩溃（Mode Collapse）是GANs中的常见问题，表现为生成的样本缺乏多样性，因为学习目标中没有明确的约束来强制生成器探索整个数据分布 。此外，为未知类别无约束地生成数据样本可能会产生与实际分布相去甚远的样本，这可能误导后续的分类器 。   

为了克服这些限制，研究者提出了多种改进策略：

- Wasserstein GAN (WGAN)：通过使用Wasserstein距离作为目标函数来缓解模式崩溃问题，并对判别器应用权重裁剪或梯度惩罚来稳定训练过程 。   

- f-CLSWGAN：引入分类损失，以鼓励生成器生成更具判别性的特征，从而提高分类性能 。   

- 循环一致性损失：确保生成的视觉特征能够映射回其各自的语义空间，从而生成更具判别性的视觉特征，并增强生成数据与语义信息之间的一致性 。
