# CADE: Detecting and Explaining Concept Drift Samples  for Security Applications
## 背景和需要解决的问题
  由于网络流量的是不停的变化的，所以对于一个基于机器学习或者深度学习的流量监测系统来说，这就意味着，他每时每刻都需要接收新的数据（可能是好的，也可能不好的也就是带有攻击性的），并进行训练。这就带来了一个问题，随着数据量越来越多，一开始分类的流量可能会出现概念漂移的现象。  
  为了理解什么是概念漂移，这里举一个简单的例子，假设在一个用于恶意流量监测的深度学习模型中，模型的训练数据是已知的恶意软件样本和正常软件样本，那么在真实的网络环境中，流量是每时每刻都进入模型进行监测的，在这个过程中，如果出现了一个全新的恶意软件，并且使用了不同于原先数据集中的代码结构和特征，甚至他在流量中的分布也不同，也就是这个恶意流量的数据在原数据集中并不存在，那么模型就会出现误判，也就是将其判断为安全的软件，也就是漏报，这就是概念漂移简单的理解。  
  所以，对于传统的机器学习和深度学习来说，如果想要保证监测的准确率，就需要每隔一段时间对模型进行重新训练，但是这种行为是非常耗费资源的，因此，这篇论文提出了一种叫做CADE的方法。
![CADE的高层次工作流程](https://github.com/makabal/paper/blob/main/tupian/CADE-1.jpg)  
  这篇文章将一个模型对新的数据的监测分成了两个空间，一个叫做Production Space，也就是模型工作的空间，一个叫做Monitoring Space也就是CADE系统工作的空间，每当新的数据进来的时候，CADE模型就会分析这个数据是否产生了数据漂移，并对其进行解释，也就是为什么会产生漂移的原因，然后告诉模型，这个应该分成一个什么类别（暂时还不知道他用的什么方法）。 
  总的来说，CADE是一种对抗概念漂移的方法。  
## CADE的实现  
[源码地址：https://github.com/whyisyoung/CADE](https://github.com/whyisyoung/CADE)  
### 漂移样本的监测  
  主要思想：并不是单纯的数据分类，而是通过对比学习的思想，将数据的相似度进行量化的比较，如果相似度高，则作为概念漂移数据的候选。  
  在这个模块中主要解决了这几个问题：  
- 如何将数据进行降维，同时又保留他的关键信息？
- 如何进行概念漂移的检测？
- 如何解释漂移样本？  
#### 如何将数据进行降维，同时又保留他的关键信息？  
![漂移监测的高层次工作流程](https://github.com/makabal/paper/blob/main/tupian/CADE-2.jpg)  
  文章采用了autoencoder，不过这个autoencoder的特殊之处在于，它增强了对比损失，所以在这篇文章中也叫做Contrastive Auto-encoder，以下是其损失函数的构造公式：  
![](https://github.com/makabal/paper/blob/main/tupian/CADE-math-1.jpg)   
  这个公式主要由两个部分组成，加号前面的部分是指重建损失，也就是确保Contrastive Auto-encoder在降维的过程中能够保留关键信息的部分，其实现的方法主要是通过将原始数据和Contrastive Auto-encoder降维再重建后的数据做差后计算欧几里得距离。  
  加号后面的部分是对比损失，为的是能够确保，同类样本靠近、异类样本分离，同样的这个部分也被分成了两个部分，前面的部分是计算同类样本，所以y=1时，也就是对于异类样本，这个部分会等于零，就是不考虑这部分了，而后半部分是计算异类样本，同样的，当y=0时，也就是对于同类样本，损失函数不考虑这部分，这两部部分都是通过计算潜在空间中的欧几里得距离来表示所谓的相似度，距离越大（大于等于𝑚），潜在表示越分离；距离越小，样本的潜在表示越接近。   
  通过Contrastive Auto-encoder的降维操作之后，就会将原本高维、复杂的数据降至低维空间，而在这个空间中，每一个类都是聚在一起的。(类似聚类)以上过程全都是Contrastive Auto-encoder的训练过程，是有标注的数据。  
### 如何进行概念漂移的检测？    
算法描述（伪代码）  
```plaintext
输入: 训练数据 X_train, 测试数据 X_test, CAE 模型 f(x; θ), h(z; φ), 参数 b
输出: 测试样本的漂移判断

1. 初始化: 计算训练阶段信息
   1.1 对每个类别 c:
       - 计算类别中心: μ_c = mean(f(x) ∀ x ∈ X_train 且 x 属于类别 c)
       - 计算距离分布: d_ic = ||f(x_i) - μ_c||_2
       - 计算阈值: τ_c = b · median(|d_ic - median(d_ic)|)

2. 测试阶段: 漂移检测
   2.1 对每个测试样本 x_t ∈ X_test:
       - 编码: z_t = f(x_t)
       - 初始化漂移标记: drift = True
       - 对每个类别 c:
           - 计算到中心的距离: d_tc = ||z_t - μ_c||_2
           - 如果 d_tc ≤ τ_c:
               - drift = False
               - 跳出类别检查循环
       - 如果 drift == True:
           - 标记 x_t 为漂移样本
   2.2 计算每个漂移样本的排名
3. 返回漂移判断结果  
```
  简单概括一下就是，如果将每一个类别看成一团低维的数据集，那么计算其质心，然后对于每一个测试样本，先通过Contrastive Auto-encoder进行降维，让其映射到之前训练好的潜在空间中，然后计算测试样本和每个类别质心的欧几里德距离，根据这个距离，就可以判断这个新的样本是否属于其中任意一个类别。
在计算出了测试样本和每个类别质心的欧几里德距离之后，显然我们需要设定一个阈值，通过距离和这个阈值的比较，来进行类别的判定。  
那么如何得到这个阈值？
  在这片文章中采用的是MAD，也就是绝对值偏差的方法，这么做的原因是，在真实情况下，每一个类别的紧密程度都是不同的，所以对于每一个类别都需要设定不同的距离阈值，如果采用手动设置，那么每更换一个数据集就需要重新设置，适应性不好，而使用MAD无需人为干预，不管是从鲁棒性还是适应性的角度，都更加的效率，准确。  
  通过MAD的计算公式，我们可以得到每一个类别所对应的MAD值，再将这个值乘上一个缩放因子b，这个b通常需要自己调节，不同任务可能需要不同的检测灵敏度：  
- 较大的𝑏： 
  - 阈值较宽松，检测灵敏度降低，可能减少误判（false positive）。    
  - 适合分布较松散的类别。  
- 较小的𝑏：  
  - 阈值较严格，检测灵敏度提高，可能减少漏检（false negative）。  
  - 适合分布较紧密的类别。

判定规则： 
- 如果存在一个类别c，是的d(距离)<t(阈值),那么则认为这个样本属于c，如果同时存在多个c，则将样本归类到距离最小的那个类别。  
- 如果对于所有的类别c，都满足d(距离)>t(阈值)，那么就认为这个样本产生了漂移。  

  在最后，通过漂移样本的距离，进行排名，距离越大排名越高表示产生漂移的可能性越大，在下一阶段的解释模块中会得到更加优先的处理。
### 如何解释漂移样本？  
  传统的监督学习模式：由于测试样本的稀疏性，难以划定决策边界，所以这种方法的效果是有局限性的，所以本文不采用这种方法。  
本文的方法  
  首先，我们需要明白，解释漂移样本是什么意思？  
  通俗的来讲就是，我们需要找到一个对样本产生概念漂移影响最大的特征，所以这个模块的作用就是找到这个特征。 
  因此，这个模块采用的是一种特征扰动的方法。  
  在之前的模块中，我们已经知道了如何判断样本是否产生了漂移，那么在这个模块中，我们通过对测试样本的原始数据进行特征的更替，也就是将测试样本中的某些特征替换成参考样本（即训练数据）的相应特征，同时观察样本和类别质心的距离，并通过距离变化来理解哪些特征对漂移产生了影响，而参考样本是训练数据中与类别质心最接近的样本。 
  如何决定替换的特征？
  在扰动之前，会将不需要扰动的特征进行筛选，因为他们已经和参考样本近似。  
  每个特征i的扰动通过Bernoulli分布决定，扰动的概率为p。  
  而Bernoulli分布是离散的，我们无法直接对m求梯度，所以将其转化成Concrete分布。  
  并通过Adam优化器对每个特征的概率p进行优化，从而找到最重要的扰动特征。  
  而扰动的目标就是让测试样本尽可能的靠近质心，也就是找出最重要的特征，这样就能知道什么特征对漂移的影响最大。  
## 效果评估  
数据集：Android malware family attribution中的Drebin数据集；Network Intrusion Detection数据集(参考文献：Iman Sharafaldin, Arash Habibi Lashkari, and Ali A Ghorbani. Toward generating a new intrusion detection dataset and intrusion traffic characterization. In Prof. of ICISSP, 2018.)  
指标：精确率、召回率、F1 分数、检查工作量的指标  
Baseline：a standard Vanilla autoencoder、Transcend  
实验结果表明，通过对降维之后的数据在潜在空间中，漂移数据和原始数据的分离度更好。  
![Drebin 数据集的原始空间和潜在空间中测试样本与其最近质心之间距离的箱线图。来自以前未见过的家族的样本被视为漂流样本。](https://github.com/makabal/paper/blob/main/tupian/CADE-3.jpg)
















 








