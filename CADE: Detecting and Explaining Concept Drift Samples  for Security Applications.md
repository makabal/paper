# CADE: Detecting and Explaining Concept Drift Samples  for Security Applications
## 背景和需要解决的问题
由于网络流量的是不停的变化的，所以对于一个基于机器学习或者深度学习的流量监测系统来说，这就意味着，他每时每刻都需要接收新的数据（可能是好的，也可能不好的也就是带有攻击性的），并进行训练。这就带来了一个问题，随着数据量越来越多，一开始分类的流量可能会出现概念漂移的现象。  
为了理解什么是概念漂移，这里举一个简单的例子，假设在一个用于恶意流量监测的深度学习模型中，模型的训练数据是已知的恶意软件样本和正常软件样本，那么在真实的网络环境中，流量是每时每刻都进入模型进行监测的，在这个过程中，如果出现了一个全新的恶意软件，并且使用了不同于原先数据集中的代码结构和特征，甚至他在流量中的分布也不同，也就是这个恶意流量的数据在原数据集中并不存在，那么模型就会出现误判，也就是将其判断为安全的软件，也就是漏报，这就是概念漂移简单的理解。  
所以，对于传统的机器学习和深度学习来说，如果想要保证监测的准确率，就需要每隔一段时间对模型进行重新训练，但是这种行为是非常耗费资源的，因此，这篇论文提出了一种叫做CADE的方法。
![CADE的高层次工作流程](https://github.com/makabal/paper/blob/main/tupian/CADE-1.jpg)  
这篇文章将一个模型对新的数据的监测分成了两个空间，一个叫做Production Space，也就是模型工作的空间，一个叫做Monitoring Space也就是CADE系统工作的空间，每当新的数据进来的时候，CADE模型就会分析这个数据是否产生了数据漂移，并对其进行解释，也就是为什么会产生漂移的原因，然后告诉模型，这个应该分成一个什么类别（暂时还不知道他用的什么方法）。 
总的来说，CADE是一种对抗概念漂移的方法。  
## CADE的实现  
[源码地址：https://github.com/whyisyoung/CADE](https://github.com/whyisyoung/CADE)  
### 漂移样本的监测  
主要思想：并不是单纯的数据分类，而是通过对比学习的思想，将数据的相似度进行量化的比较，如果相似度高，则作为概念漂移数据的候选。  
在这个模块中主要解决了这几个问题：  
- 如何将数据进行降维，同时又保留他的关键信息？
- 如何进行概念漂移的检测？  
#### 如何将数据进行降维，同时又保留他的关键信息？  
![漂移监测的高层次工作流程](https://github.com/makabal/paper/blob/main/tupian/CADE-2.jpg)  
文章采用了autoencoder，不过这个autoencoder的特殊之处在于，它增强了对比损失，所以在这篇文章中也叫做Contrastive Auto-encoder，以下是其损失函数的构造公式：  
![](https://github.com/makabal/paper/blob/main/tupian/CADE-math-1.jpg)   
这个公式主要由两个部分组成，加号前面的部分是指重建损失，也就是确保Contrastive Auto-encoder在降维的过程中能够保留关键信息的部分，其实现的方法主要是通过将原始数据和Contrastive Auto-encoder降维再重建后的数据做差后计算欧几里得距离。  
加号后面的部分是对比损失，为的是能够确保，同类样本靠近、异类样本分离，同样的这个部分也被分成了两个部分，前面的部分是计算同类样本，所以y=1时，也就是对于异类样本，这个部分会等于零，就是不考虑这部分了，而后半部分是计算异类样本，同样的，当y=0时，也就是对于同类样本，损失函数不考虑这部分，这两部部分都是通过计算潜在空间中的欧几里得距离来表示所谓的相似度，距离越大（大于等于𝑚），潜在表示越分离；距离越小，样本的潜在表示越接近。   
通过Contrastive Auto-encoder的降维操作之后，就会将原本高维、复杂的数据降至低维空间，而在这个空间中，每一个类都是聚在一起的。(类似聚类)以上过程全都是Contrastive Auto-encoder的训练过程，是有标注的数据。  
### 如何进行概念漂移的检测  
算法描述（伪代码）  
```plaintext
输入: 训练数据 X_train, 测试数据 X_test, CAE 模型 f(x; θ), h(z; φ), 参数 b
输出: 测试样本的漂移判断

1. 初始化: 计算训练阶段信息
   1.1 对每个类别 c:
       - 计算类别中心: μ_c = mean(f(x) ∀ x ∈ X_train 且 x 属于类别 c)
       - 计算距离分布: d_ic = ||f(x_i) - μ_c||_2
       - 计算阈值: τ_c = b · median(|d_ic - median(d_ic)|)

2. 测试阶段: 漂移检测
   2.1 对每个测试样本 x_t ∈ X_test:
       - 编码: z_t = f(x_t)
       - 初始化漂移标记: drift = True
       - 对每个类别 c:
           - 计算到中心的距离: d_tc = ||z_t - μ_c||_2
           - 如果 d_tc ≤ τ_c:
               - drift = False
               - 跳出类别检查循环
       - 如果 drift == True:
           - 标记 x_t 为漂移样本

3. 返回漂移判断结果  
简单概括一下就是，如果将每一个类别看成一团低维的数据集，那么计算其质心，然后对于每一个测试样本，先通过Contrastive Auto-encoder进行降维，让其映射到之前训练好的潜在空间中，然后计算测试样本和每个类别质心的欧几里德距离，根据这个距离，就可以判断这个新的样本是否属于其中任意一个类别。
在计算出了测试样本和每个类别质心的欧几里德距离之后，显然我们需要设定一个阈值，通过距离和这个阈值的比较，来进行类别的判定。  
那么如何得到这个阈值？
在这片文章中采用的是MAD，也就是绝对值偏差的方法，这么做的原因是，在真实情况下，每一个类别的紧密程度都是不同的，所以对于每一个类别都需要设定不同的距离阈值，如果采用手动设置，那么每更换一个数据集就需要重新设置，适应性不好，而使用MAD无需人为干预，不管是从鲁棒性还是适应性的角度，都更加的效率，准确。  
通过MAD的计算公式，我们可以得到每一个类别所对应的MAD值，再将这个值乘上一个缩放因子b，这个b通常需要自己调节，不同任务可能需要不同的检测灵敏度：  
- 较大的𝑏： 
  - 阈值较宽松，检测灵敏度降低，可能减少误判（false positive）。
  - 适合分布较松散的类别。  
- 较小的𝑏：
  - 阈值较严格，检测灵敏度提高，可能减少漏检（false negative）。
  - 适合分布较紧密的类别。






 








